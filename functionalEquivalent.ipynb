{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e86a52b",
   "metadata": {},
   "source": [
    "# Excluded Unknown Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e7484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "072d95c9",
   "metadata": {},
   "source": [
    "# Gather Functional equivalent results from ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3d2f53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 3001...\n",
      "Processing row 3002...\n",
      "Processing row 3003...\n",
      "Processing row 3004...\n",
      "Processing row 3005...\n",
      "Processing row 3006...\n",
      "Processing row 3007...\n",
      "Processing row 3008...\n",
      "Processing row 3009...\n",
      "Processing row 3010...\n",
      "Processing row 3011...\n",
      "Processing row 3012...\n",
      "Processing row 3013...\n",
      "Processing row 3014...\n",
      "Processing row 3015...\n",
      "Processing row 3016...\n",
      "Processing row 3017...\n",
      "Processing row 3018...\n",
      "Processing row 3019...\n",
      "Processing row 3020...\n",
      "Processing row 3021...\n",
      "Processing row 3022...\n",
      "Processing row 3023...\n",
      "Processing row 3024...\n",
      "Processing row 3025...\n",
      "Processing row 3026...\n",
      "Processing row 3027...\n",
      "Processing row 3028...\n",
      "Processing row 3029...\n",
      "Processing row 3030...\n",
      "Processing row 3031...\n",
      "Processing row 3032...\n",
      "Processing row 3033...\n",
      "Processing row 3034...\n",
      "Processing row 3035...\n",
      "Processing row 3036...\n",
      "Processing row 3037...\n",
      "Processing row 3038...\n",
      "Processing row 3039...\n",
      "Processing row 3040...\n",
      "Processing row 3041...\n",
      "Processing row 3042...\n",
      "Processing row 3043...\n",
      "Processing row 3044...\n",
      "Processing row 3045...\n",
      "Processing row 3046...\n",
      "Processing row 3047...\n",
      "Processing row 3048...\n",
      "Processing row 3049...\n",
      "Processing row 3050...\n",
      "Processing row 3051...\n",
      "Processing row 3052...\n",
      "Processing row 3053...\n",
      "Processing row 3054...\n",
      "Processing row 3055...\n",
      "Processing row 3056...\n",
      "Processing row 3057...\n",
      "Processing row 3058...\n",
      "Processing row 3059...\n",
      "Processing row 3060...\n",
      "Processing row 3061...\n",
      "Processing row 3062...\n",
      "Processing row 3063...\n",
      "Processing row 3064...\n",
      "Processing row 3065...\n",
      "Processing row 3066...\n",
      "Processing row 3067...\n",
      "Processing row 3068...\n",
      "Processing row 3069...\n",
      "Processing row 3070...\n",
      "Processing row 3071...\n",
      "Processing row 3072...\n",
      "Processing row 3073...\n",
      "Processing row 3074...\n",
      "Processing row 3075...\n",
      "Processing row 3076...\n",
      "Processing row 3077...\n",
      "Processing row 3078...\n",
      "Processing row 3079...\n",
      "Processing row 3080...\n",
      "Processing row 3081...\n",
      "Processing row 3082...\n",
      "Processing row 3083...\n",
      "Processing row 3084...\n",
      "Processing row 3085...\n",
      "Processing row 3086...\n",
      "Processing row 3087...\n",
      "Processing row 3088...\n",
      "Processing row 3089...\n",
      "Processing row 3090...\n",
      "Processing row 3091...\n",
      "Processing row 3092...\n",
      "Processing row 3093...\n",
      "Processing row 3094...\n",
      "Processing row 3095...\n",
      "Processing row 3096...\n",
      "Processing row 3097...\n",
      "Processing row 3098...\n",
      "Processing row 3099...\n",
      "Processing row 3100...\n",
      "‚úÖ Results saved to full_equiv_output3_NoMismatch_3001_3100_YesNoOnly_gpt-4o_tempEquals0.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# ========== User Configuration ==========\n",
    "input_file = \"full_equiv_output3_NoMismatch.xlsx\" # This version of xlsx contains how many pass and fail solutions each problem has.\n",
    "startline = 3001\n",
    "endline = 3100\n",
    "model_name = \"gpt-4o\"\n",
    "output_file = f\"full_equiv_output3_NoMismatch_{startline}_{endline}_YesNoOnly_{model_name}_tempEquals0.xlsx\"\n",
    "\n",
    "# ========================================\n",
    "\n",
    "# --- Helper: Remove comments from C++, Java, and Python code ---\n",
    "def remove_comments(code: str) -> str:\n",
    "    # Remove /* ... */ block comments\n",
    "    code = re.sub(r\"/\\*.*?\\*/\", \"\", code, flags=re.DOTALL)\n",
    "    # Remove // single-line comments\n",
    "    code = re.sub(r\"//.*\", \"\", code)\n",
    "    # Remove # single-line comments (Python)\n",
    "    code = re.sub(r\"#.*\", \"\", code)\n",
    "    # Remove Python triple-quoted strings (\"\"\" ... \"\"\" or ''' ... ''')\n",
    "    code = re.sub(r'\"\"\".*?\"\"\"', \"\", code, flags=re.DOTALL)\n",
    "    code = re.sub(r\"'''.*?'''\", \"\", code, flags=re.DOTALL)\n",
    "    return code.strip()\n",
    "\n",
    "# Load Excel data\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Define comparison pairs\n",
    "pairs = [\n",
    "    \n",
    "    (\"CPP_Pass1\", \"CPP_Pass2\"),\n",
    "    (\"JAVA_Pass1\", \"JAVA_Pass2\"),\n",
    "    (\"PYTHON3_Pass1\", \"PYTHON3_Pass2\"),\n",
    "    (\"CPP_Pass1\", \"CPP_Fail\"),\n",
    "    (\"JAVA_Pass1\", \"JAVA_Fail\"),\n",
    "    (\"PYTHON3_Pass1\", \"PYTHON3_Fail\"),\n",
    "    (\"CPP_Pass1\", \"JAVA_Pass1\"),\n",
    "    (\"JAVA_Pass1\", \"PYTHON3_Pass1\"),\n",
    "    (\"PYTHON3_Pass1\", \"CPP_Pass1\"),\n",
    "]\n",
    "\n",
    "# Create result columns (only Yes/No)\n",
    "for col1, col2 in pairs:\n",
    "    df[f\"{col1}_vs_{col2}\"] = \"\"\n",
    "\n",
    "# Process rows\n",
    "for idx in range(startline - 1, min(endline, len(df))):\n",
    "    row = df.iloc[idx]\n",
    "    print(f\"Processing row {idx + 1}...\")\n",
    "\n",
    "    problem = str(row.get(\"Description\", \"\")).strip()\n",
    "\n",
    "    for col1, col2 in pairs:\n",
    "        code1 = str(row.get(col1, \"\")).strip()\n",
    "        code2 = str(row.get(col2, \"\")).strip()\n",
    "\n",
    "        if not code1 or not code2:\n",
    "            continue\n",
    "\n",
    "        # Remove comments\n",
    "        clean_code1 = remove_comments(code1)\n",
    "        clean_code2 = remove_comments(code2)\n",
    "\n",
    "        # Prompt: only Yes/No\n",
    "        prompt = f\"\"\"\n",
    "You are a software analysis expert.\n",
    "\n",
    "Determine if the following two code snippets (<code1> and <code2>) \n",
    "that aim to solve the problem (<Problem>) are functional equivalent. We define functional equivalence as two code snippets having the same input‚Äìoutput pairs. Ignore internal differences and focus only on whether the outputs are the same for identical inputs.\n",
    "\n",
    "Reply with only one word: \"Yes\" or \"No\". \n",
    "Do not explain anything.\n",
    "\n",
    "<Problem>\n",
    "{problem}\n",
    "</Problem>\n",
    "\n",
    "<code1>\n",
    "{clean_code1}\n",
    "</code1>\n",
    "\n",
    "<code2>\n",
    "{clean_code2}\n",
    "</code2>\n",
    "\"\"\"\n",
    "        # print(prompt)\n",
    "        # Query GPT\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a software analysis expert.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature = 0,\n",
    "            )\n",
    "\n",
    "            answer = response.choices[0].message.content.strip()\n",
    "            # Normalize to \"Yes\" or \"No\"\n",
    "            if answer.lower().startswith(\"y\"):\n",
    "                df.at[idx, f\"{col1}_vs_{col2}\"] = \"Yes\"\n",
    "            elif answer.lower().startswith(\"n\"):\n",
    "                df.at[idx, f\"{col1}_vs_{col2}\"] = \"No\"\n",
    "            else:\n",
    "                df.at[idx, f\"{col1}_vs_{col2}\"] = \"Unclear\"\n",
    "\n",
    "        except Exception as e:\n",
    "            df.at[idx, f\"{col1}_vs_{col2}\"] = f\"Error: {str(e)}\"\n",
    "\n",
    "# Save the result\n",
    "df.to_excel(output_file, index=False)\n",
    "print(f\"‚úÖ Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ef0bf",
   "metadata": {},
   "source": [
    "# Calculate Column Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf5695d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "üìà All combined charts saved to: c:\\Users\\Hui Sun\\Dropbox\\Code Readbility LLM\\ComparativeComprehensionLLM\\charts_output_3001_3100\n",
      "  ‚úÖ Total Yes: 444\n",
      "  ‚ùå Total No:  456\n",
      "\n",
      "üìä Accuracy Summary:\n",
      "                        Column  Yes  No  Accuracy\n",
      "        CPP_Pass1_vs_CPP_Pass2   67  33     67.00\n",
      "      JAVA_Pass1_vs_JAVA_Pass2   69  31     69.00\n",
      "PYTHON3_Pass1_vs_PYTHON3_Pass2   60  40     60.00\n",
      "         CPP_Pass1_vs_CPP_Fail   28  72     72.00\n",
      "       JAVA_Pass1_vs_JAVA_Fail   39  61     61.00\n",
      " PYTHON3_Pass1_vs_PYTHON3_Fail   22  78     78.00\n",
      "       CPP_Pass1_vs_JAVA_Pass1   63  37     63.00\n",
      "   JAVA_Pass1_vs_PYTHON3_Pass1   55  45     55.00\n",
      "    PYTHON3_Pass1_vs_CPP_Pass1   41  59     41.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ========== ÈÖçÁΩÆ ==========\n",
    "input_file = \"full_equiv_output3_NoMismatch_3001_3100_YesNoOnly_gpt-4o_tempEquals0.xlsx\"\n",
    "output_dir = \"charts_output_3001_3100\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "columns_to_check = [\n",
    "    \"CPP_Pass1_vs_CPP_Pass2\",\n",
    "    \"JAVA_Pass1_vs_JAVA_Pass2\",\n",
    "    \"PYTHON3_Pass1_vs_PYTHON3_Pass2\",\n",
    "    \"CPP_Pass1_vs_CPP_Fail\",\n",
    "    \"JAVA_Pass1_vs_JAVA_Fail\",\n",
    "    \"PYTHON3_Pass1_vs_PYTHON3_Fail\",\n",
    "    \"CPP_Pass1_vs_JAVA_Pass1\",\n",
    "    \"JAVA_Pass1_vs_PYTHON3_Pass1\",\n",
    "    \"PYTHON3_Pass1_vs_CPP_Pass1\"\n",
    "]\n",
    "\n",
    "difficulty_col = \"Difficulty\"\n",
    "# =========================\n",
    "\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "if difficulty_col not in df.columns:\n",
    "    raise ValueError(f\"‚ùå Column '{difficulty_col}' not found in Excel!\")\n",
    "\n",
    "df[difficulty_col] = df[difficulty_col].astype(str).str.strip()\n",
    "\n",
    "total_yes = 0\n",
    "total_no = 0\n",
    "summary_data = []\n",
    "\n",
    "# ---------- ÂàõÂª∫Â§ßÁîªÂ∏É (3√ó3) ----------\n",
    "fig_overall, axs_overall = plt.subplots(3, 3, figsize=(15, 12))\n",
    "fig_difficulty, axs_diff = plt.subplots(3, 3, figsize=(18, 14))\n",
    "\n",
    "axs_overall = axs_overall.flatten()\n",
    "axs_diff = axs_diff.flatten()\n",
    "\n",
    "def compute_accuracy(col_name, yes_count, no_count):\n",
    "    total = yes_count + no_count\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    if \"Pass\" in col_name and \"Fail\" in col_name:\n",
    "        return no_count / total * 100  # No ÊòØÊ≠£Á°ÆÁ≠îÊ°à\n",
    "    else:\n",
    "        return yes_count / total * 100  # Yes ÊòØÊ≠£Á°ÆÁ≠îÊ°à\n",
    "\n",
    "for i, col in enumerate(columns_to_check):\n",
    "    if col not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Warning: Column '{col}' not found in Excel.\")\n",
    "        continue\n",
    "\n",
    "    df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "    yes_count = (df[col] == \"yes\").sum()\n",
    "    no_count = (df[col] == \"no\").sum()\n",
    "    total_yes += yes_count\n",
    "    total_no += no_count\n",
    "    acc = compute_accuracy(col, yes_count, no_count)\n",
    "    summary_data.append([col, yes_count, no_count, acc])\n",
    "\n",
    "    # === Overall Yes/No ===\n",
    "    ax = axs_overall[i]\n",
    "    bars = ax.bar([\"Yes\", \"No\"], [yes_count, no_count], color=[\"green\", \"red\"])\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height + 1, f\"{height}\", \n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "    ax.set_title(f\"{col}\\nAcc: {acc:.1f}%\", fontsize=10)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "    # === By Difficulty ===\n",
    "    grouped = df.groupby(difficulty_col)[col].value_counts().unstack(fill_value=0)\n",
    "    grouped = grouped.reindex(columns=[\"yes\", \"no\"], fill_value=0)\n",
    "    grouped.plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        color=[\"#4CAF50\", \"#F44336\"],\n",
    "        ax=axs_diff[i],\n",
    "        legend=False\n",
    "    )\n",
    "\n",
    "    # ËÆ°ÁÆóÊØè‰∏™ÈöæÂ∫¶ÁöÑÊ≠£Á°ÆÁéáÂπ∂Âú®Êü±‰∏äÊ†áÊ≥®\n",
    "    for idx, (diff, row) in enumerate(grouped.iterrows()):\n",
    "        y, n = row.get(\"yes\", 0), row.get(\"no\", 0)\n",
    "        acc_diff = compute_accuracy(col, y, n)\n",
    "        axs_diff[i].text(idx, y + n + 0.5, f\"{acc_diff:.1f}%\", ha=\"center\", fontsize=8, color=\"blue\")\n",
    "\n",
    "    axs_diff[i].set_title(f\"{col}\\nAcc by Diff\", fontsize=10)\n",
    "    axs_diff[i].set_xlabel(\"Difficulty\")\n",
    "    axs_diff[i].set_ylabel(\"Count\")\n",
    "    axs_diff[i].grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "# ---------- Ë∞ÉÊï¥Â∏ÉÂ±ÄÂπ∂‰øùÂ≠ò ----------\n",
    "for fig in [fig_overall, fig_difficulty]:\n",
    "    fig.tight_layout(pad=3.0)\n",
    "\n",
    "fig_overall.suptitle(\"Overall Yes/No Counts (with Accuracy%)\", fontsize=16, y=1.02)\n",
    "fig_difficulty.suptitle(\"Yes/No by Difficulty (with Accuracy%)\", fontsize=16, y=1.02)\n",
    "\n",
    "fig_overall.savefig(os.path.join(output_dir, \"ALL_overall_with_accuracy.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "fig_difficulty.savefig(os.path.join(output_dir, \"ALL_by_difficulty_with_accuracy.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.close(fig_overall)\n",
    "plt.close(fig_difficulty)\n",
    "\n",
    "# === ÊÄªÊ±áÊÄª ===\n",
    "summary_df = pd.DataFrame(summary_data, columns=[\"Column\", \"Yes\", \"No\", \"Accuracy\"])\n",
    "summary_df.plot(\n",
    "    x=\"Column\",\n",
    "    y=[\"Yes\", \"No\"],\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    color=[\"#4CAF50\", \"#F44336\"],\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "plt.title(\"Overall Yes/No Count per Column\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"overall_summary_single.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === ËæìÂá∫ÊéßÂà∂Âè∞ÁªüËÆ° ===\n",
    "print(\"\\n===========================\")\n",
    "print(\"üìà All combined charts saved to:\", os.path.abspath(output_dir))\n",
    "print(f\"  ‚úÖ Total Yes: {total_yes}\")\n",
    "print(f\"  ‚ùå Total No:  {total_no}\")\n",
    "print(\"\\nüìä Accuracy Summary:\")\n",
    "print(summary_df.to_string(index=False, float_format=\"%.2f\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff64aa6",
   "metadata": {},
   "source": [
    "# GPT-5 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ef1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Loading Excel file...\n",
      "‚úÖ Loaded 6905 rows from full_equiv_output3_NoMismatch.xlsx\n",
      "\n",
      "üöÄ [ROW 1] Start processing...\n",
      "üß© Problem name: 1000_A. Codehorses T-shirts\n",
      "üß† Preparing prompt for CPP_Pass1 vs CPP_Pass2 ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n",
      "üì• Response received in 110.18s\n",
      "üí¨ GPT answer: No\n",
      "üß† Preparing prompt for JAVA_Pass1 vs JAVA_Pass2 ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n",
      "üì• Response received in 21.68s\n",
      "üí¨ GPT answer: No\n",
      "üß† Preparing prompt for PYTHON3_Pass1 vs PYTHON3_Pass2 ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n",
      "üì• Response received in 15.92s\n",
      "üí¨ GPT answer: Yes\n",
      "üß† Preparing prompt for CPP_Pass1 vs CPP_Fail ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n",
      "üì• Response received in 40.13s\n",
      "üí¨ GPT answer: No\n",
      "üß† Preparing prompt for JAVA_Pass1 vs JAVA_Fail ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n",
      "üì• Response received in 18.82s\n",
      "üí¨ GPT answer: No\n",
      "üß† Preparing prompt for PYTHON3_Pass1 vs PYTHON3_Fail ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n",
      "üì• Response received in 16.13s\n",
      "üí¨ GPT answer: No\n",
      "üß† Preparing prompt for CPP_Pass1 vs JAVA_Pass1 ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n",
      "üì• Response received in 30.85s\n",
      "üí¨ GPT answer: No\n",
      "üß† Preparing prompt for JAVA_Pass1 vs PYTHON3_Pass1 ...\n",
      "üì§ Sending request to ChatGPT (gpt-5-mini)...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import traceback\n",
    "\n",
    "# ===============================\n",
    "# Initialize OpenAI client\n",
    "# ===============================\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# ========== User Configuration ==========\n",
    "input_file = \"full_equiv_output3_NoMismatch.xlsx\"\n",
    "startline = 1\n",
    "endline = 3\n",
    "output_file = f\"full_equiv_output3_NoMismatch_{startline}_{endline}_YesNoOnly_GPT5_log.xlsx\"\n",
    "model_name = \"gpt-5-mini\"  \n",
    "# ========================================\n",
    "\n",
    "# --- Helper: Remove comments ---\n",
    "def remove_comments(code: str) -> str:\n",
    "    code = re.sub(r\"/\\*.*?\\*/\", \"\", code, flags=re.DOTALL)\n",
    "    code = re.sub(r\"//.*\", \"\", code)\n",
    "    code = re.sub(r\"#.*\", \"\", code)\n",
    "    code = re.sub(r'\"\"\".*?\"\"\"', \"\", code, flags=re.DOTALL)\n",
    "    code = re.sub(r\"'''.*?'''\", \"\", code, flags=re.DOTALL)\n",
    "    return code.strip()\n",
    "\n",
    "# --- Load Excel ---\n",
    "print(\"üìñ Loading Excel file...\")\n",
    "df = pd.read_excel(input_file)\n",
    "print(f\"‚úÖ Loaded {len(df)} rows from {input_file}\")\n",
    "\n",
    "# --- Define pairs ---\n",
    "pairs = [\n",
    "    (\"CPP_Pass1\", \"CPP_Pass2\"),\n",
    "    (\"JAVA_Pass1\", \"JAVA_Pass2\"),\n",
    "    (\"PYTHON3_Pass1\", \"PYTHON3_Pass2\"),\n",
    "    (\"CPP_Pass1\", \"CPP_Fail\"),\n",
    "    (\"JAVA_Pass1\", \"JAVA_Fail\"),\n",
    "    (\"PYTHON3_Pass1\", \"PYTHON3_Fail\"),\n",
    "    (\"CPP_Pass1\", \"JAVA_Pass1\"),\n",
    "    (\"JAVA_Pass1\", \"PYTHON3_Pass1\"),\n",
    "    (\"PYTHON3_Pass1\", \"CPP_Pass1\"),\n",
    "]\n",
    "\n",
    "# --- Create result columns ---\n",
    "for col1, col2 in pairs:\n",
    "    df[f\"{col1}_vs_{col2}\"] = \"\"\n",
    "\n",
    "# --- Main loop ---\n",
    "for idx in range(startline - 1, min(endline, len(df))):\n",
    "    row = df.iloc[idx]\n",
    "    print(f\"\\nüöÄ [ROW {idx + 1}] Start processing...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    problem = str(row.get(\"Description\", \"\")).strip()\n",
    "    print(f\"üß© Problem name: {problem[:80]}{'...' if len(problem) > 80 else ''}\")\n",
    "\n",
    "    for col1, col2 in pairs:\n",
    "        out_col = f\"{col1}_vs_{col2}\"\n",
    "        code1 = str(row.get(col1, \"\")).strip()\n",
    "        code2 = str(row.get(col2, \"\")).strip()\n",
    "\n",
    "        if not code1 or not code2:\n",
    "            print(f\"‚ö†Ô∏è  {col1} or {col2} missing ‚Äî skipping\")\n",
    "            df.at[idx, out_col] = \"Unclear\"\n",
    "            continue\n",
    "\n",
    "        clean_code1 = remove_comments(code1)\n",
    "        clean_code2 = remove_comments(code2)\n",
    "\n",
    "        print(f\"üß† Preparing prompt for {col1} vs {col2} ...\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are a software analysis expert.\n",
    "\n",
    "Determine if the following two code snippets (<code1> and <code2>) \n",
    "that aim to solve the problem (<Problem>) are functionally equivalent.\n",
    "Definition: they produce the SAME input-output mapping for all valid inputs of the problem.\n",
    "Ignore inner implementation differences; only focus on input/output pairs.\n",
    "\n",
    "Reply with only one word: \"Yes\" or \"No\".\n",
    "Do not explain anything.\n",
    "\n",
    "<Problem>\n",
    "{problem}\n",
    "</Problem>\n",
    "\n",
    "<code1>\n",
    "{clean_code1}\n",
    "</code1>\n",
    "\n",
    "<code2>\n",
    "{clean_code2}\n",
    "</code2>\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            print(f\"üì§ Sending request to ChatGPT ({model_name})...\")\n",
    "            start_api = time.time()\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a software analysis expert.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                timeout=120  # ÊúÄÈïøÁ≠â 2 ÂàÜÈíü\n",
    "            )\n",
    "            print(f\"üì• Response received in {round(time.time() - start_api, 2)}s\")\n",
    "\n",
    "            answer = response.choices[0].message.content.strip()\n",
    "            print(f\"üí¨ GPT answer: {answer[:50]}{'...' if len(answer) > 50 else ''}\")\n",
    "\n",
    "            ans_lower = answer.lower()\n",
    "            if ans_lower.startswith(\"y\"):\n",
    "                df.at[idx, out_col] = \"Yes\"\n",
    "            elif ans_lower.startswith(\"n\"):\n",
    "                df.at[idx, out_col] = \"No\"\n",
    "            else:\n",
    "                df.at[idx, out_col] = \"Unclear\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR during {col1} vs {col2}: {type(e).__name__}\")\n",
    "            traceback.print_exc()\n",
    "            df.at[idx, out_col] = f\"Error: {type(e).__name__}: {str(e)}\"\n",
    "\n",
    "    print(f\"‚úÖ [ROW {idx + 1}] Finished in {round(time.time() - t0, 2)}s\")\n",
    "\n",
    "# --- Save output ---\n",
    "df.to_excel(output_file, index=False)\n",
    "print(f\"\\nüéâ All done! Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe64e54",
   "metadata": {},
   "source": [
    "# Save code into folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Êï∞ÊçÆÂ∑≤ÂØºÂá∫Ëá≥Ôºöc:\\Users\\Hui Sun\\Dropbox\\Code Readbility LLM\\ComparativeComprehensionLLM\\Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "input_file = \"full_equiv_output3_NoMismatch_1_101_YesNoOnly_gpt-4o_tempEquals0.xlsx\"\n",
    "start_line = 1   \n",
    "end_line = 101   \n",
    "output_base = \"Code\"\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "\n",
    "columns_to_export = [\n",
    "    \"CPP_Pass1\", \"CPP_Pass2\", \"CPP_Fail\",\n",
    "    \"JAVA_Pass1\", \"JAVA_Pass2\", \"JAVA_Fail\",\n",
    "    \"PYTHON3_Pass1\", \"PYTHON3_Pass2\", \"PYTHON3_Fail\"\n",
    "]\n",
    "\n",
    "\n",
    "columns_to_export = [c for c in columns_to_export if c in df.columns]\n",
    "\n",
    "for idx in range(start_line - 1, min(end_line, len(df))):\n",
    "    row = df.iloc[idx]\n",
    "    problem_name = str(row.get(\"ProblemName\", f\"Row_{idx+1}\"))\n",
    "    \n",
    "\n",
    "    folder_name = re.sub(r'[<>:\"/\\\\|?*]', '_', problem_name)\n",
    "    folder_path = os.path.join(output_base, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    for col in columns_to_export:\n",
    "        value = str(row.get(col, \"\")).strip()\n",
    "        file_path = os.path.join(folder_path, f\"{col}.txt\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(value)\n",
    "\n",
    "print(f\"‚úÖ Saved toÔºö{os.path.abspath(output_base)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00fce8",
   "metadata": {},
   "source": [
    "# QWen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Áî®‰∏ÄÂè•ËØùËß£ÈáäÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂ∑•‰ΩúÂéüÁêÜ„ÄÇ\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
